{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "average_sequential.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQkH9OF8reo7",
        "colab_type": "code",
        "outputId": "3e45c214-f88c-484c-b9fa-79be6442a8a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import keras\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import gzip\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Model\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.layers import Input,Dense,Flatten,Dropout,merge,Reshape\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Model,Sequential\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.optimizers import Adadelta, RMSprop,SGD,Adam\n",
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train.astype('float32')/255\n",
        "X_test = X_test.astype('float32')/255\n",
        "X_train = X_train.reshape(len(X_train), np.prod(X_train.shape[1:]))\n",
        "X_test = X_test.reshape(len(X_test), np.prod(X_test.shape[1:]))\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "\n",
        "batch_size = 64\n",
        "epochs = 50\n",
        "inChannel = 1\n",
        "x, y = 28, 28\n",
        "input_img = Input(shape = (x, y, inChannel))\n",
        "num_classes = 10\n",
        "\n",
        "X_train = X_train/np.max(X_train)\n",
        "X_test = X_test/np.max(X_test)\n",
        "\n",
        "print(np.max(X_train))\n",
        "train_X,valid_X,train_ground,valid_ground = train_test_split(X_train,\n",
        "                                                             X_train,\n",
        "                                                             test_size=0.2,\n",
        "                                                             random_state=13)\n",
        "\n",
        "input_img = Input(shape = (784,))\n",
        "num_classes = 10\n",
        "\n",
        "def Encoder_part(input_img):\n",
        "\n",
        "    encoded = Dense(units=256, activation='relu')(input_img)\n",
        "    encoded = Dense(units=128, activation='relu')(encoded)\n",
        "    encoded = Dense(units=64, activation='relu')(encoded)\n",
        "    encoded = Dense(units=32, activation='relu')(encoded)\n",
        "\n",
        "    return encoded\n",
        "\n",
        "def Decoder_part(encoded):\n",
        "        \n",
        "    decoded = Dense(units=64, activation='relu')(encoded)\n",
        "    decoded = Dense(units=128, activation='relu')(decoded)\n",
        "    decoded = Dense(units=256, activation='relu')(decoded)\n",
        "    decoded = Dense(units=784, activation='relu')(decoded)\n",
        "    \n",
        "    return decoded"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0710 06:45:04.699297 140633170593664 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0710 06:45:04.719494 140633170593664 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URijeWSJ1uON",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7a613ed-ac10-44b8-9f4f-9dc41fdcee76"
      },
      "source": [
        "autoencoder1=Model(input_img, Decoder_part(Encoder_part(input_img)))\n",
        "autoencoder2=Model(input_img, Decoder_part(Encoder_part(input_img)))\n",
        "#autoencoder3=Model(input_img, Decoder_part(Encoder_part(input_img)))\n",
        "#autoencoder4=Model(input_img, Decoder_part(Encoder_part(input_img)))\n",
        "#autoencoder5=Model(input_img, Decoder_part(Encoder_part(input_img)))\n",
        "autoencoder_final=Model(input_img, Decoder_part(Encoder_part(input_img)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0710 06:46:34.456463 140633170593664 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAloY0wzso1i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#encoder = Model(input_img, Encoder_part(input_img))\n",
        "\n",
        "autoencoder1.compile(loss='mean_squared_error', optimizer = SGD())\n",
        "autoencoder2.compile(loss='mean_squared_error', optimizer = SGD())\n",
        "#autoencoder3.compile(loss='mean_squared_error', optimizer = SGD())\n",
        "#autoencoder4.compile(loss='mean_squared_error', optimizer = SGD())\n",
        "#autoencoder5.compile(loss='mean_squared_error', optimizer = SGD())\n",
        "autoencoder_final.compile(loss='mean_squared_error', optimizer = SGD())\n",
        "\n",
        "autoencoder1.summary()\n",
        "autoencoder2.summary()\n",
        "#autoencoder3.summary()\n",
        "#autoencoder4.summary()\n",
        "#autoencoder5.summary()\n",
        "autoencoder_final.summary()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwpv6AsLR7pN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(train_X[1][1])\n",
        "#print(np.shape(train_X))\n",
        "batch_train_X = []\n",
        "batch_train_ground = []\n",
        "\n",
        "i=0\n",
        "while i < 48000:\n",
        "  x  = []\n",
        "  j = 0\n",
        "  while j<1000:\n",
        "    x.append(train_X[i])\n",
        "    j = j+1\n",
        "    i = i+1\n",
        "  print(i)\n",
        "  batch_train_X.append(x)\n",
        "print(\"done\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAyIO94uYz4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(np.shape(train_X))\n",
        "print(np.shape(batch_train_ground))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xdl94PI_9ig8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i=0\n",
        "while i < 48000:\n",
        "  x  = []\n",
        "  j = 0\n",
        "  while j<1000:\n",
        "    x.append(train_ground[i])\n",
        "    j = j+1\n",
        "    i = i+1\n",
        "  print(i)\n",
        "  batch_train_ground.append(x)\n",
        "print(\"done\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L066HK2Hd6hr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(batch_train_X[47][999])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3C8-BkEXo-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_X = valid_X[:1000]\n",
        "valid_ground = valid_ground[:1000]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuqOcgB7i8r1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(np.shape(train_X))\n",
        "print(np.shape(i))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COpqUI8478ih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count = 0\n",
        "number = 0\n",
        "for epo in range (0,75):\n",
        "  number = 0\n",
        "  print(\"entered first loop : \", epo)\n",
        "  for i,j in zip(batch_train_X,batch_train_ground):\n",
        "    print(\"entered second loop : \")\n",
        "    number = number + 1\n",
        "    i = [i]\n",
        "    j = [j]\n",
        "    print(\"**************************************************************************************************************8\")\n",
        "    print(\"batch : \" , number, \"epoch : \", epo)\n",
        "    if count == 0:\n",
        "      print(\"Entered if 1\", count)\n",
        "      autoencoder_train1 = autoencoder1.fit(i,j, batch_size=1000,epochs=1,verbose=1,validation_data=(valid_X, valid_ground))\n",
        "      count = count+1\n",
        "    if count == 1:\n",
        "      print(\"Entered if 2\", count)\n",
        "      autoencoder_train2 = autoencoder2.fit(i,j, batch_size=1000,epochs=1,verbose=1,validation_data=(valid_X, valid_ground))\n",
        "      count = count+1\n",
        "    #if count == 2:  \n",
        "    #  autoencoder_train3 = autoencoder3.fit(i,j, batch_size=1,epochs=epochs,verbose=1,validation_data=(valid_X, valid_ground))\n",
        "    #if count == 3:  \n",
        "    #  autoencoder_train4 = autoencoder4.fit(i,j, batch_size=1,epochs=epochs,verbose=1,validation_data=(valid_X, valid_ground))\n",
        "    #if count ==4:  \n",
        "    #  autoencoder_train5 = autoencoder5.fit(i,j, batch_size=1,epochs=epochs,verbose=1,validation_data=(valid_X, valid_ground))\n",
        "    if count ==2:\n",
        "      print(\"Entered if 3\", count)\n",
        "      count = 0\n",
        "      w1 = np.array(autoencoder1.get_weights())\n",
        "      w2 = np.array(autoencoder2.get_weights())\n",
        "      #w3 = autoencoder3.get_weights()\n",
        "      #w4 = autoencoder4.get_weights()\n",
        "      #w5 = autoencoder5.get_weights()\n",
        "      w_final = (w1+w2)/2\n",
        "      \n",
        "      print(\"Taken weights\")\n",
        "      \n",
        "      w_cur = np.array(autoencoder_final.get_weights())\n",
        "      w_final = (w_cur+w_final)/2\n",
        "\n",
        "      \n",
        "    \n",
        "      print(\"Meaned weights\")\n",
        "    \n",
        "      \n",
        "    \n",
        "      autoencoder_final.set_weights(w_final)\n",
        "      autoencoder1.set_weights(w_final)\n",
        "      autoencoder2.set_weights(w_final)\n",
        "      #autoencoder3.set_weights(w_final)\n",
        "      #autoencoder4.set_weights(w_final)\n",
        "      #autoencoder5.set_weights(w_final)\n",
        "      #autoencoder.set_weights(w_final)\n",
        "      \n",
        "      print(\"Going to the top again\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SxxKWzsiw42",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = autoencoder_train1.history['loss']\n",
        "val_loss = autoencoder_train1.history['val_loss']\n",
        "epochs = range(100)\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "loss = autoencoder_train2.history['loss']\n",
        "val_loss = autoencoder_train2.history['val_loss']\n",
        "epochs = range(100)\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}